import asyncio
import aiosqlite
import re
from datetime import datetime, timedelta
from playwright.async_api import async_playwright
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import json

DB_FILE = "aweme_full.db"

# åˆå§‹åŒ–æ•°æ®åº“


async def init_db():
    async with aiosqlite.connect(DB_FILE) as db:
        await db.execute("""
        CREATE TABLE IF NOT EXISTS videos (
            video_id TEXT PRIMARY KEY,
            title TEXT,
            hashtags TEXT,
            is_ads INTEGER,
            duration REAL,
            publish_time TEXT,
            play_count INTEGER,
            digg_count INTEGER,
            comment_count INTEGER,
            share_url TEXT,
            cover_url TEXT,
            video_url TEXT,
            author_id TEXT,
            author_name TEXT,
            author_avatar TEXT,
            music_id TEXT,
            music_title TEXT,
            music_author TEXT,
            update_time TEXT
        )
        
        CREATE TABLE IF NOT EXISTS products (
            product_id INTEGER PRIMARY KEY AUTOINCREMENT,
            product_name TEXT,
            product_keywords TEXT,
            first_seen_date TEXT,
            last_seen_date TEXT,
            video_count INTEGER DEFAULT 0,
            total_play_count INTEGER DEFAULT 0,
            total_digg_count INTEGER DEFAULT 0,
            growth_rate REAL DEFAULT 0.0,
            popularity_score REAL DEFAULT 0.0,
            author_id TEXT,
            author_name TEXT
        )
        
        CREATE TABLE IF NOT EXISTS video_product_mapping (
            video_id TEXT,
            product_id INTEGER,
            PRIMARY KEY (video_id, product_id),
            FOREIGN KEY (video_id) REFERENCES videos(video_id),
            FOREIGN KEY (product_id) REFERENCES products(product_id)
        )
        """)
        await db.commit()

# å¤„ç†å“åº”


async def handle_response(response, db):
    url = response.url
    if "aweme/v1/web/aweme/post" in url:
        try:
            data = await response.json()
            aweme_list = data.get("aweme_list", [])
            if not aweme_list:
                return

            async with db.execute("BEGIN"):
                for item in aweme_list:
                    video_id = item.get("aweme_id")
                    if not video_id:
                        continue

                    # æŸ¥è¯¢æ˜¯å¦å·²å­˜åœ¨
                    async with db.execute("SELECT 1 FROM videos WHERE video_id=?", (video_id,)) as cursor:
                        if await cursor.fetchone():
                            continue

                    # è§†é¢‘ä¿¡æ¯
                    desc = item.get("desc", "")
                    hashtags = [h.get("hashtag_name", "") for h in (
                        item.get("text_extra") or []) if h.get("hashtag_name")]
                    hashtags_str = ",".join(hashtags)
                    is_ads = item.get("is_ads") or 0
                    duration = item.get("duration", 0) / 1000
                    create_time = item.get("create_time")
                    publish_time = datetime.fromtimestamp(create_time).strftime(
                        "%Y-%m-%d %H:%M:%S") if create_time else ""
                    stats = item.get("statistics") or {}
                    play_count = stats.get("play_count", 0)
                    digg_count = stats.get("digg_count", 0)
                    comment_count = stats.get("comment_count", 0)
                    share_url = item.get("share_info", {}).get("share_url", "")
                    cover_url = (item.get("video", {}).get(
                        "cover", {}).get("url_list") or [""])[0]
                    video_url = (item.get("video", {}).get(
                        "play_addr", {}).get("url_list") or [""])[0]

                    author = item.get("author") or {}
                    author_id = author.get("uid", "")
                    author_name = author.get("nickname", "")
                    author_avatar = (author.get(
                        "avatar_thumb", {}).get("url_list") or [""])[0]

                    music = item.get("music") or {}
                    music_id = music.get("id", "")
                    music_title = music.get("title", "")
                    music_author = music.get("author", "")

                    # æ’å…¥æ•°æ®åº“
                    await db.execute("""
                        INSERT OR REPLACE INTO videos (
                            video_id, title, hashtags, is_ads, duration, publish_time,
                            play_count, digg_count, comment_count, share_url, cover_url,
                            video_url, author_id, author_name, author_avatar,
                            music_id, music_title, music_author, update_time
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        video_id, desc, hashtags_str, is_ads, duration, publish_time,
                        play_count, digg_count, comment_count, share_url, cover_url,
                        video_url, author_id, author_name, author_avatar,
                        music_id, music_title, music_author, datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    ))
                    
                    # æå–äº§å“ä¿¡æ¯
                    await extract_products_from_video(db, item, author_id, author_name)
                    print(f"âœ… æ’å…¥è§†é¢‘ {video_id} - {desc[:20]}")

                await db.commit()
        except Exception as e:
            print("âŒ å¤„ç†æ•°æ®å‡ºé”™:", e)

# ä¸»è¿è¡Œå‡½æ•°


async def run(urls):
    await init_db()
    async with aiosqlite.connect(DB_FILE) as db:
        async with async_playwright() as p:
            browser = await p.chromium.launch_persistent_context(
                user_data_dir="/Users/bairdweng/Library/Application Support/Google/Chrome/Default",
                channel="chrome",
                headless=False
            )
            page = await browser.new_page()

            # æ¯æ¬¡æŠ“å–å‰ç»‘å®š response äº‹ä»¶
            page.on("response", lambda response: asyncio.create_task(
                handle_response(response, db)))

            for url in urls:
                print(f"ğŸ”¹ å¼€å§‹æŠ“å– {url}")
                await page.goto(url)
                await asyncio.sleep(20)  # ç­‰å¾…ç½‘ç»œè¯·æ±‚è§¦å‘

            print("âœ… æŠ“å–å®Œæˆï¼Œä¿æŒæµè§ˆå™¨æ‰“å¼€ 60 ç§’")
            await asyncio.sleep(60)
            await browser.close()
            
            # åˆ†æçƒ­å–å’Œå¢é•¿äº§å“
            print("ğŸ” åˆ†æçƒ­å–å’Œå¢é•¿äº§å“...")
            await analyze_hot_products(db)
            await analyze_growth_products(db)

# å®šä¹‰è¦æŠ“å–çš„ç”¨æˆ·URLåˆ—è¡¨
DEFAULT_URLS = [
    "https://www.douyin.com/user/MS4wLjABAAAA75EbUN-VEfEiyyidKjBKLw4vza41ET_RS8PK_2LySF6UugM_nPdFUKBEb_-2gX2m",  # ç¿æ™Ÿæ•°ç ä¸¥é€‰å·¥ä½œå®¤è®¤è¯å¾½ç« 
    "https://www.douyin.com/user/MS4wLjABAAAAD-_Dk8WpxkT43dZ-Ib5pza05hI7LKsWo3jR766miHKftsKGdvITpEz48-hZKwXCw",  # tutu
    "https://www.douyin.com/user/MS4wLjABAAAAAXviISIVZECvu_zsrSC812o7cx6HWQDJMALk-CwR8cTNu0KoqF0YJwooVwdhYykE",  # å¯¹çš„
    "https://www.douyin.com/user/MS4wLjABAAAALoETvdflpmaXqD5jQxReulB_qxkcP34JNBI24kdEyZw",  # å®ˆæŠ¤è€…
    "https://www.douyin.com/user/MS4wLjABAAAAIiLGcuZGSJxc4okvtGARBEpx4N4VDDw1tmyB6JG2viQ"  # å£³å²¸
]

# å®šæ—¶ä»»åŠ¡å‡½æ•°
async def scheduled_task():
    print(f"\nğŸ“… å¼€å§‹å®šæ—¶æŠ“å–ä»»åŠ¡ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    try:
        await run(DEFAULT_URLS)
        print(f"âœ… å®šæ—¶æŠ“å–ä»»åŠ¡å®Œæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        print(f"âŒ å®šæ—¶æŠ“å–ä»»åŠ¡å‡ºé”™: {e}")

# å¯åŠ¨å®šæ—¶ä»»åŠ¡
async def start_scheduler():
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = AsyncIOScheduler()
    
    # æ·»åŠ æ¯å¤©æ‰§è¡Œä¸€æ¬¡çš„ä»»åŠ¡ï¼ˆé»˜è®¤åœ¨å‡Œæ™¨1ç‚¹æ‰§è¡Œï¼‰
    scheduler.add_job(
        scheduled_task,
        trigger=CronTrigger(hour=1, minute=0),  # æ¯å¤©å‡Œæ™¨1ç‚¹æ‰§è¡Œ
        id='daily_scrape',
        name='æŠ–éŸ³ç”¨æˆ·è§†é¢‘æ¯å¤©æŠ“å–',
        replace_existing=True
    )
    
    # å¯åŠ¨è°ƒåº¦å™¨
    scheduler.start()
    print(f"ğŸš€ å®šæ—¶ä»»åŠ¡å·²å¯åŠ¨ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ“… æ¯å¤©å‡Œæ™¨1:00è‡ªåŠ¨æ‰§è¡ŒæŠ“å–ä»»åŠ¡")
    print("ğŸ”„ æŒ‰ Ctrl+C åœæ­¢ä»»åŠ¡")
    
    # ç«‹å³æ‰§è¡Œä¸€æ¬¡æŠ“å–ä»»åŠ¡
    print("\nğŸ”„ ç«‹å³æ‰§è¡Œä¸€æ¬¡æŠ“å–ä»»åŠ¡")
    await scheduled_task()
    
    # ä¿æŒç¨‹åºè¿è¡Œ
    try:
        while True:
            await asyncio.sleep(86400)  # ç¡çœ ä¸€å¤©
    except KeyboardInterrupt:
        print("\nğŸ›‘ å®šæ—¶ä»»åŠ¡å·²åœæ­¢")
        scheduler.shutdown()

async def extract_products_from_video(db, video_item, author_id, author_name):
    """ä»è§†é¢‘å†…å®¹ä¸­æå–äº§å“ä¿¡æ¯"""
    try:
        title = video_item.get("desc", "")
        hashtags = [h.get("hashtag_name", "") for h in (video_item.get("text_extra") or []) if h.get("hashtag_name")]
        video_id = video_item.get("aweme_id")
        
        # å¢å¼ºçš„äº§å“å…³é”®è¯æ¨¡å¼ï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
        product_categories = {
            'å“ç‰Œ': [r'åä¸º|è‹¹æœ|å°ç±³|OPPO|vivo|ä¸‰æ˜Ÿ|è£è€€|realme|ä¸€åŠ |é­…æ—'],
            'å‹å·': [r'Mate[0-9]+|P[0-9]+|iPhone[0-9]+|iPhone SE|iPhone X[0-9]*|Pro|Max|Ultra|Plus|Note[0-9]+|S[0-9]+'],
            'äº§å“ç±»å‹': [r'æ‰‹æœºå£³|ä¿æŠ¤å¥—|æ‰‹æœºè†œ|é’¢åŒ–è†œ|ä¿æŠ¤å£³|å……ç”µå™¨|æ•°æ®çº¿|å……ç”µå®|è€³æœº|æ”¯æ¶|æ•£çƒ­èƒŒå¤¹|æ‰‹æœºæ”¯æ¶'],
            'ç‰¹è‰²æ¬¾': [r'ä¿æ—¶æ·|éå‡¡å¤§å¸ˆ|å…¸è—ç‰ˆ|é™é‡ç‰ˆ|è”åæ¬¾|å®šåˆ¶æ¬¾|é€æ˜æ¬¾|ç£¨ç ‚æ¬¾|æ¶²æ€ç¡…èƒ¶|å…¨åŒ…æ¬¾|é˜²æ‘”æ¬¾'],
            'åŠŸèƒ½': [r'é˜²æ‘”|é˜²æ°´|å…¨åŒ…|æ•£çƒ­|å¿«å……|æ— çº¿å……|ç£å¸|éšå½¢æ”¯æ¶|é•œå¤´ä¿æŠ¤|é˜²æŒ‡çº¹']
        }
        
        # æå–å¯èƒ½çš„äº§å“å…³é”®è¯
        found_products = []
        product_info = {}
        
        # æŒ‰ç±»åˆ«æå–å…³é”®è¯
        for category, patterns in product_categories.items():
            category_matches = []
            for pattern in patterns:
                # ä»æ ‡é¢˜æå–
                matches = re.findall(pattern, title)
                category_matches.extend(matches)
                # ä»hashtagæå–
                for hashtag in hashtags:
                    if re.search(pattern, hashtag):
                        category_matches.append(hashtag)
            
            if category_matches:
                # å»é‡å¹¶ä¿å­˜åˆ°äº§å“ä¿¡æ¯ä¸­
                product_info[category] = list(set(category_matches))
                found_products.extend(category_matches)
        
        # åˆå¹¶ç»“æœï¼Œç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„äº§å“åç§°
        enhanced_products = []
        
        # ä¼˜å…ˆç»„åˆå“ç‰Œ+å‹å·+äº§å“ç±»å‹çš„å®Œæ•´äº§å“åç§°
        if 'å“ç‰Œ' in product_info and 'å‹å·' in product_info and 'äº§å“ç±»å‹' in product_info:
            for brand in product_info['å“ç‰Œ']:
                for model in product_info['å‹å·']:
                    for product_type in product_info['äº§å“ç±»å‹']:
                        enhanced_products.append(f"{brand}{model}{product_type}")
        
        # å¦‚æœæ²¡æœ‰å®Œæ•´ç»„åˆï¼Œä½¿ç”¨å•ä¸€å…³é”®è¯
        if not enhanced_products:
            enhanced_products = list(set(found_products))
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°äº§å“ï¼Œå°è¯•æ›´ç®€å•çš„å…³é”®è¯æå–
        if not enhanced_products:
            simple_keywords = re.findall(r'[\u4e00-\u9fa5]{2,}', title)
            # è¿‡æ»¤æ‰å¸¸è§éäº§å“è¯æ±‡
            common_words = {'è¿™ä¸ª', 'é‚£ä¸ª', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½'}
            simple_keywords = [word for word in simple_keywords if len(word) >= 2 and word not in common_words]
            enhanced_products = simple_keywords[:3]  # æœ€å¤šå–3ä¸ªå¯èƒ½çš„å…³é”®è¯
        
        # ä¿å­˜æ‰¾åˆ°çš„äº§å“
        for product_keyword in enhanced_products[:5]:  # æœ€å¤šå¤„ç†5ä¸ªäº§å“
            product_keyword = product_keyword[:50]  # é™åˆ¶é•¿åº¦
            
            # æŸ¥æ‰¾æˆ–åˆ›å»ºäº§å“è®°å½•
            async with db.execute(
                "SELECT product_id FROM products WHERE product_keywords LIKE ? AND author_id = ?",
                (f"%{product_keyword}%", author_id)
            ) as cursor:
                existing = await cursor.fetchone()
                
            if existing:
                product_id = existing[0]
                # æ›´æ–°äº§å“ä¿¡æ¯
                await db.execute(
                    "UPDATE products SET last_seen_date = ?, video_count = video_count + 1 WHERE product_id = ?",
                    (datetime.now().strftime("%Y-%m-%d"), product_id)
                )
            else:
                # ç¡®å®šäº§å“ç±»åˆ«
                product_category = "å…¶ä»–"
                for category, patterns in product_categories.items():
                    for pattern in patterns:
                        if re.search(pattern, product_keyword):
                            product_category = category
                            break
                
                # åˆ›å»ºæ–°äº§å“
                await db.execute(
                    """
                    INSERT INTO products 
                    (product_name, product_keywords, first_seen_date, last_seen_date, video_count, 
                     author_id, author_name, growth_rate, popularity_score)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (product_keyword, product_keyword, datetime.now().strftime("%Y-%m-%d"), 
                     datetime.now().strftime("%Y-%m-%d"), 1, author_id, author_name, 0.0, 0.0)
                )
                product_id = await db.execute("SELECT last_insert_rowid()")
                product_id = (await product_id.fetchone())[0]
                
                # å»ºç«‹è§†é¢‘å’Œäº§å“çš„æ˜ å°„å…³ç³»
                try:
                    await db.execute(
                        "INSERT OR IGNORE INTO video_product_mapping (video_id, product_id) VALUES (?, ?)",
                        (video_id, product_id)
                    )
                except:
                    pass  # å¿½ç•¥é‡å¤æ’å…¥é”™è¯¯
        
    except Exception as e:
        print(f"âŒ æå–äº§å“ä¿¡æ¯å‡ºé”™: {e}")

async def update_product_scores(db):
    """æ›´æ–°äº§å“çš„çƒ­åº¦å’Œå¢é•¿åˆ†æ•° - æš‚æ—¶è·³è¿‡å¤æ‚è®¡ç®—"""
    try:
        # ç®€åŒ–ç‰ˆï¼šç›´æ¥è®¾ç½®ä¸€ä¸ªåŸºç¡€åˆ†æ•°ï¼Œé¿å…SQLè¯­æ³•é—®é¢˜
        await db.execute("UPDATE products SET popularity_score = 10.0")
        await db.commit()
    except Exception as e:
        print(f"âŒ æ›´æ–°äº§å“åˆ†æ•°å‡ºé”™: {e}")
        await db.rollback()

async def analyze_hot_products(db, days=7):
    """åˆ†ææœ€è¿‘çƒ­å–çš„äº§å“ - å®Œå…¨ç®€åŒ–ç‰ˆ"""
    try:
        # ç®€åŒ–ç‰ˆæŸ¥è¯¢ï¼Œåªè¿”å›éœ€è¦çš„å­—æ®µ
        query = """
        SELECT p.product_id, p.product_name, COUNT(DISTINCT v.video_id) as video_count,
               SUM(v.play_count) as total_plays, SUM(v.digg_count) as total_likes,
               p.author_name, AVG(v.play_count) as avg_plays
        FROM products p
        JOIN video_product_mapping vpm ON p.product_id = vpm.product_id
        JOIN videos v ON vpm.video_id = v.video_id
        GROUP BY p.product_id, p.product_name
        ORDER BY SUM(v.play_count) DESC
        LIMIT 10
        """
        
        async with db.execute(query) as cursor:
            hot_products = await cursor.fetchall()
        
        if hot_products:
            print(f"\nğŸ”¥ æœ€è¿‘çƒ­å–äº§å“TOP10:")
            print("-" * 80)
            print(f"{'æ’å':<5}{'äº§å“åç§°':<25}{'è§†é¢‘æ•°':<10}{'æ’­æ”¾é‡':<15}{'ç‚¹èµæ•°':<10}{'åº—é“º'}")
            print("-" * 80)
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            filename = f"hot_products_{datetime.now().strftime('%Y%m%d')}.txt"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"ğŸ”¥ çƒ­å–äº§å“TOP10 (ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n")
                f.write("-" * 80 + "\n")
                f.write(f"{'æ’å':<5}{'äº§å“åç§°':<25}{'è§†é¢‘æ•°':<10}{'æ’­æ”¾é‡':<15}{'ç‚¹èµæ•°':<10}{'åº—é“º'}\n")
                f.write("-" * 80 + "\n")
                
                for i, product in enumerate(hot_products, 1):
                    # ç¡®ä¿è§£åŒ…æ­£ç¡® - ç°åœ¨æŸ¥è¯¢è¿”å›7ä¸ªå­—æ®µ
                    product_id, name, video_count, plays, likes, author, avg_plays = product
                    author_truncated = author[:15] if len(author) > 15 else author
                    print(f"{i:<5}{name[:23]:<25}{video_count:<10}{plays:<15,}{likes:<10,}{author_truncated}")
                    f.write(f"{i:<5}{name[:23]:<25}{video_count:<10}{plays:<15,}{likes:<10,}{author}\n")
            
            print(f"\nâœ… çƒ­å–äº§å“æŠ¥å‘Šå·²ä¿å­˜è‡³ {filename}")
        else:
            print("\nğŸ“¢ æš‚æ— çƒ­å–äº§å“æ•°æ®")
        
    except Exception as e:
        print(f"âŒ åˆ†æçƒ­å–äº§å“å‡ºé”™: {e}")

async def analyze_growth_products(db, days=7):
    """åˆ†ææ½œåœ¨å¢é•¿äº§å“ - ä½¿ç”¨ç®€åŒ–æ–¹æ³•"""
    try:
        today = datetime.now()
        
        # ç®€åŒ–ç‰ˆï¼šåŸºäºè§†é¢‘æ•°å’Œæ’­æ”¾é‡è¿›è¡Œæ’åº
        query = """
        SELECT p.product_id, p.product_name, p.author_name,
               COUNT(DISTINCT v.video_id) as video_count,
               SUM(v.play_count) as total_plays,
               SUM(v.digg_count) as total_likes
        FROM products p
        JOIN video_product_mapping vpm ON p.product_id = vpm.product_id
        JOIN videos v ON vpm.video_id = v.video_id
        GROUP BY p.product_id, p.product_name
        HAVING COUNT(DISTINCT v.video_id) > 0 AND SUM(v.play_count) > 30
        ORDER BY 
            COUNT(DISTINCT v.video_id) DESC, 
            SUM(v.play_count) DESC
        LIMIT 10
        """
        
        async with db.execute(query) as cursor:
            growth_data = await cursor.fetchall()
        
        if growth_data:
            print(f"\nğŸ“ˆ æ½œåœ¨å¢é•¿äº§å“TOP10:")
            print("-" * 80)
            print(f"{'æ’å':<5}{'äº§å“åç§°':<25}{'è§†é¢‘æ•°':<10}{'æ’­æ”¾é‡':<15}{'ç‚¹èµæ•°':<10}{'åº—é“º'}")
            print("-" * 80)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            filename = f"growth_products_{datetime.now().strftime('%Y%m%d')}.txt"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"ğŸ“ˆ æ½œåœ¨å¢é•¿äº§å“åˆ†æ (ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})\n")
                f.write(f"ğŸ“… åˆ†ææ—¥æœŸ: {today.strftime('%Y-%m-%d')}\n\n")
                f.write("-" * 80 + "\n")
                f.write(f"{'æ’å':<5}{'äº§å“åç§°':<25}{'è§†é¢‘æ•°':<10}{'æ’­æ”¾é‡':<15}{'ç‚¹èµæ•°':<10}{'åº—é“º'}\n")
                f.write("-" * 80 + "\n")
                
                for i, product in enumerate(growth_data, 1):
                    # è§£åŒ…æ­£ç¡®çš„å­—æ®µæ•°é‡
                    product_id, name, author, video_count, total_plays, total_likes = product
                    author_truncated = author[:15] if len(author) > 15 else author
                    print(f"{i:<5}{name[:23]:<25}{video_count:<10}{total_plays:<15,}{total_likes:<10,}{author_truncated}")
                    f.write(f"{i:<5}{name[:23]:<25}{video_count:<10}{total_plays:<15,}{total_likes:<10,}{author}\n")
            
            print(f"\nâœ… æ½œåœ¨å¢é•¿äº§å“æŠ¥å‘Šå·²ä¿å­˜è‡³ {filename}")
        else:
            print("\nğŸ“ˆ æš‚æ— è¶³å¤Ÿæ•°æ®è¿›è¡Œå¢é•¿äº§å“åˆ†æ")
            print("   å»ºè®®: ç»§ç»­æ”¶é›†æ›´å¤šè§†é¢‘æ•°æ®ä»¥è¿›è¡Œè¶‹åŠ¿åˆ†æ")
            
    except Exception as e:
        print(f"âŒ åˆ†æå¢é•¿äº§å“å‡ºé”™: {e}")
        # å¦‚æœå‡ºé”™ï¼Œå°è¯•ä¸€ä¸ªæ›´ç®€å•çš„åˆ†ææ–¹æ³•
        try:
            simple_query = """
            SELECT p.product_name, p.video_count, p.author_name
            FROM products p
            ORDER BY p.video_count DESC
            LIMIT 5
            """
            async with db.execute(simple_query) as cursor:
                simple_products = await cursor.fetchall()
                
            if simple_products:
                print("\nğŸ“ˆ ç®€æ˜“äº§å“åˆ†æç»“æœ:")
                for product in simple_products:
                    print(f"- {product[0]} ({product[2]}): {product[1]}ä¸ªç›¸å…³è§†é¢‘")
        except:
            pass

async def init_database(db):
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
    try:
        # åˆ›å»ºvideosè¡¨ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™å¿½ç•¥ï¼‰
        await db.execute("""
            CREATE TABLE IF NOT EXISTS videos (
                video_id TEXT PRIMARY KEY,
                title TEXT,
                hashtags TEXT,
                is_ads INTEGER,
                duration REAL,
                publish_time TEXT,
                play_count INTEGER,
                digg_count INTEGER,
                comment_count INTEGER,
                share_url TEXT,
                cover_url TEXT,
                video_url TEXT,
                author_id TEXT,
                author_name TEXT,
                author_avatar TEXT,
                music_id TEXT,
                music_title TEXT,
                music_author TEXT,
                update_time TEXT
            )
        """)
        
        # åˆ›å»ºproductsè¡¨ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™å¿½ç•¥ï¼‰
        await db.execute("""
            CREATE TABLE IF NOT EXISTS products (
                product_id INTEGER PRIMARY KEY AUTOINCREMENT,
                product_name TEXT,
                product_keywords TEXT,
                first_seen_date TEXT,
                last_seen_date TEXT,
                video_count INTEGER DEFAULT 0,
                total_play_count INTEGER DEFAULT 0,
                total_digg_count INTEGER DEFAULT 0,
                growth_rate REAL DEFAULT 0.0,
                popularity_score REAL DEFAULT 0.0,
                author_id TEXT,
                author_name TEXT
            )
        """)
        
        # åˆ›å»ºvideo_product_mappingè¡¨ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™å¿½ç•¥ï¼‰
        await db.execute("""
            CREATE TABLE IF NOT EXISTS video_product_mapping (
                video_id TEXT,
                product_id INTEGER,
                PRIMARY KEY (video_id, product_id),
                FOREIGN KEY (video_id) REFERENCES videos(video_id),
                FOREIGN KEY (product_id) REFERENCES products(product_id)
            )
        """)
        
        await db.commit()
        print("âœ… æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å‡ºé”™: {e}")
        await db.rollback()

async def extract_products_from_existing_videos(db):
    """ä»ç°æœ‰è§†é¢‘ä¸­æå–äº§å“ä¿¡æ¯"""
    try:
        # ç»Ÿè®¡è§†é¢‘æ•°é‡
        async with db.execute("SELECT COUNT(*) FROM videos") as cursor:
            total_videos = (await cursor.fetchone())[0]
        
        print(f"â„¹ï¸  å¼€å§‹ä» {total_videos} ä¸ªè§†é¢‘ä¸­æå–äº§å“ä¿¡æ¯...")
        
        # å¢å¼ºçš„äº§å“å…³é”®è¯æ¨¡å¼ï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
        product_categories = {
            'å“ç‰Œ': [r'åä¸º|è‹¹æœ|å°ç±³|OPPO|vivo|ä¸‰æ˜Ÿ|è£è€€|realme|ä¸€åŠ |é­…æ—'],
            'å‹å·': [r'Mate[0-9]+|P[0-9]+|iPhone[0-9]+|iPhone SE|iPhone X[0-9]*|Pro|Max|Ultra|Plus|Note[0-9]+|S[0-9]+'],
            'äº§å“ç±»å‹': [r'æ‰‹æœºå£³|ä¿æŠ¤å¥—|æ‰‹æœºè†œ|é’¢åŒ–è†œ|ä¿æŠ¤å£³|å……ç”µå™¨|æ•°æ®çº¿|å……ç”µå®|è€³æœº|æ”¯æ¶|æ•£çƒ­èƒŒå¤¹|æ‰‹æœºæ”¯æ¶'],
            'ç‰¹è‰²æ¬¾': [r'ä¿æ—¶æ·|éå‡¡å¤§å¸ˆ|å…¸è—ç‰ˆ|é™é‡ç‰ˆ|è”åæ¬¾|å®šåˆ¶æ¬¾|é€æ˜æ¬¾|ç£¨ç ‚æ¬¾|æ¶²æ€ç¡…èƒ¶|å…¨åŒ…æ¬¾|é˜²æ‘”æ¬¾'],
            'åŠŸèƒ½': [r'é˜²æ‘”|é˜²æ°´|å…¨åŒ…|æ•£çƒ­|å¿«å……|æ— çº¿å……|ç£å¸|éšå½¢æ”¯æ¶|é•œå¤´ä¿æŠ¤|é˜²æŒ‡çº¹']
        }
        
        # åˆ†æ‰¹å¤„ç†è§†é¢‘ä»¥é¿å…å†…å­˜é—®é¢˜
        batch_size = 100
        processed = 0
        
        while processed < total_videos:
            async with db.execute(
                "SELECT video_id, title, author_id, author_name, publish_time FROM videos LIMIT ? OFFSET ?",
                (batch_size, processed)
            ) as cursor:
                videos_batch = await cursor.fetchall()
                
            if not videos_batch:
                break
            
            for video in videos_batch:
                video_id, title, author_id, author_name, publish_time = video
                
                try:
                    # æå–äº§å“å…³é”®è¯
                    found_products = []
                    product_info = {}
                    
                    # æŒ‰ç±»åˆ«æå–å…³é”®è¯
                    for category, patterns in product_categories.items():
                        category_matches = []
                        for pattern in patterns:
                            matches = re.findall(pattern, title)
                            category_matches.extend(matches)
                        
                        if category_matches:
                            product_info[category] = list(set(category_matches))
                            found_products.extend(category_matches)
                    
                    # ç”Ÿæˆå¢å¼ºçš„äº§å“åç§°
                    enhanced_products = []
                    
                    # ä¼˜å…ˆç»„åˆå“ç‰Œ+å‹å·+äº§å“ç±»å‹
                    if 'å“ç‰Œ' in product_info and 'å‹å·' in product_info and 'äº§å“ç±»å‹' in product_info:
                        for brand in product_info['å“ç‰Œ']:
                            for model in product_info['å‹å·']:
                                for product_type in product_info['äº§å“ç±»å‹']:
                                    enhanced_products.append(f"{brand}{model}{product_type}")
                    
                    # å¦‚æœæ²¡æœ‰å®Œæ•´ç»„åˆï¼Œä½¿ç”¨å•ä¸€å…³é”®è¯
                    if not enhanced_products and found_products:
                        enhanced_products = list(set(found_products))
                    
                    # å¤„ç†æ¯ä¸ªæ‰¾åˆ°çš„äº§å“
                    for product_keyword in enhanced_products[:3]:  # é™åˆ¶æ•°é‡
                        product_keyword = product_keyword[:50]  # é™åˆ¶é•¿åº¦
                        
                        # æŸ¥æ‰¾æˆ–åˆ›å»ºäº§å“è®°å½•
                        async with db.execute(
                            "SELECT product_id FROM products WHERE product_keywords LIKE ? AND author_id = ?",
                            (f"%{product_keyword}%", author_id)
                        ) as pcursor:
                            existing = await pcursor.fetchone()
                            
                        if existing:
                            product_id = existing[0]
                            # æ›´æ–°äº§å“ä¿¡æ¯
                            await db.execute(
                                "UPDATE products SET last_seen_date = ?, video_count = video_count + 1 WHERE product_id = ?",
                                (datetime.now().strftime("%Y-%m-%d"), product_id)
                            )
                        else:
                            # åˆ›å»ºæ–°äº§å“
                            await db.execute(
                                """
                                INSERT INTO products 
                                (product_name, product_keywords, first_seen_date, last_seen_date, video_count, 
                                 author_id, author_name)
                                VALUES (?, ?, ?, ?, ?, ?, ?)
                                """,
                                (product_keyword, product_keyword, publish_time.split(' ')[0] if publish_time else "2024-01-01", 
                                 datetime.now().strftime("%Y-%m-%d"), 1, author_id, author_name)
                            )
                            product_id = await db.execute("SELECT last_insert_rowid()")
                            product_id = (await product_id.fetchone())[0]
                        
                        # å»ºç«‹æ˜ å°„å…³ç³»
                        try:
                            await db.execute(
                                "INSERT OR IGNORE INTO video_product_mapping (video_id, product_id) VALUES (?, ?)",
                                (video_id, product_id)
                            )
                        except:
                            pass
                    
                except Exception as e:
                    # å¿½ç•¥å•ä¸ªè§†é¢‘çš„é”™è¯¯ï¼Œç»§ç»­å¤„ç†
                    pass
            
            processed += len(videos_batch)
            await db.commit()
            print(f"â³ å·²å¤„ç† {processed}/{total_videos} ä¸ªè§†é¢‘...")
        
        # ç»Ÿè®¡æå–çš„äº§å“æ•°é‡
        async with db.execute("SELECT COUNT(*) FROM products") as cursor:
            total_products = (await cursor.fetchone())[0]
        
        print(f"âœ… äº§å“ä¿¡æ¯æå–å®Œæˆï¼å…±æå– {total_products} ä¸ªäº§å“")
        
    except Exception as e:
        print(f"âŒ æå–äº§å“ä¿¡æ¯å‡ºé”™: {e}")
        await db.rollback()

async def generate_combined_report(db):
    """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
    try:
        report_date = datetime.now().strftime("%Y-%m-%d")
        report_filename = f"competitor_analysis_{report_date}.txt"
        
        with open(report_filename, "w", encoding="utf-8") as f:
            f.write(f"ğŸ“Š ç«äº‰åº—é“ºäº§å“åˆ†æç»¼åˆæŠ¥å‘Š\n")
            f.write(f"ğŸ“… ç”Ÿæˆæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            async with db.execute("SELECT COUNT(*) FROM videos") as cursor:
                total_videos = (await cursor.fetchone())[0]
            
            async with db.execute("SELECT COUNT(*) FROM products") as cursor:
                total_products = (await cursor.fetchone())[0]
            
            async with db.execute("SELECT COUNT(DISTINCT author_id) FROM videos") as cursor:
                total_shops = (await cursor.fetchone())[0]
            
            f.write(f"ğŸ“‹ æ•°æ®æ¦‚è§ˆ\n")
            f.write(f"- æŠ“å–è§†é¢‘æ€»æ•°: {total_videos:,}\n")
            f.write(f"- è¯†åˆ«äº§å“æ€»æ•°: {total_products}\n")
            f.write(f"- ç›‘æ§åº—é“ºæ•°: {total_shops}\n\n")
            
            # çƒ­é—¨åº—é“ºTOP5
            f.write(f"ğŸ† çƒ­é—¨åº—é“ºTOP5 (æŒ‰è§†é¢‘æ•°)\n")
            async with db.execute(
                "SELECT author_name, COUNT(*) as video_count FROM videos GROUP BY author_name ORDER BY video_count DESC LIMIT 5"
            ) as cursor:
                top_shops = await cursor.fetchall()
                for i, shop in enumerate(top_shops, 1):
                    f.write(f"{i}. {shop[0]}: {shop[1]} ä¸ªè§†é¢‘\n")
            
            f.write("\n" + "="*60 + "\n\n")
        
        print(f"âœ… ç»¼åˆåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_filename}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆç»¼åˆæŠ¥å‘Šå‡ºé”™: {e}")

# å¢åŠ ä¸€ä¸ªæ‰‹åŠ¨åˆ†æå‘½ä»¤è¡ŒåŠŸèƒ½
async def analyze_existing_data():
    """åˆ†æå·²å­˜åœ¨çš„æ•°æ®ï¼Œæ‰¾å‡ºçƒ­å–å’Œå¢é•¿äº§å“"""
    print("ğŸ” å¼€å§‹åˆ†æå·²æœ‰æ•°æ®ä¸­çš„çƒ­å–å’Œå¢é•¿äº§å“...")
    async with aiosqlite.connect(DB_FILE) as db:
        # ç¡®ä¿è¡¨ç»“æ„å­˜åœ¨
        await init_database(db)
        
        # å¦‚æœproductsè¡¨ä¸ºç©ºï¼Œå°è¯•ä»ç°æœ‰è§†é¢‘ä¸­æå–äº§å“ä¿¡æ¯
        async with db.execute("SELECT COUNT(*) FROM products") as cursor:
            count = (await cursor.fetchone())[0]
        
        if count == 0:
            await extract_products_from_existing_videos(db)
        else:
            print(f"â„¹ï¸  æ£€æµ‹åˆ°å·²æœ‰ {count} ä¸ªäº§å“è®°å½•")
        
        # æ‰§è¡Œåˆ†æ
        print("\nğŸ“Š å¼€å§‹æ‰§è¡Œäº§å“åˆ†æ...")
        await analyze_hot_products(db)
        await analyze_growth_products(db)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        await generate_combined_report(db)
        
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("   â€¢ çƒ­å–äº§å“åˆ†æåŸºäºæ’­æ”¾é‡å’Œç‚¹èµæ•°çš„ç»¼åˆæƒé‡")
        print("   â€¢ å¢é•¿è¶‹åŠ¿åˆ†ææ¯”è¾ƒæœ€è¿‘7å¤©å’Œä¹‹å‰7å¤©çš„è¡¨ç°")
        print("   â€¢ ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶ä¿å­˜åœ¨å½“å‰ç›®å½•")
        print("   â€¢ å®šæœŸè¿è¡Œ 'python index.py analyze' å¯æŒç»­ç›‘æ§ç«å“åŠ¨æ€")
        print("   â€¢ ç›´æ¥è¿è¡Œè„šæœ¬å¯æŠ“å–æœ€æ–°è§†é¢‘å¹¶è‡ªåŠ¨åˆ†æ")
    
    print("\nâœ… æ•°æ®åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    import sys
    
    # å¦‚æœå‚æ•°ä¸­åŒ…å« analyzeï¼Œåˆ™åªæ‰§è¡Œåˆ†æè€Œä¸æŠ“å–
    if len(sys.argv) > 1 and sys.argv[1] == "analyze":
        asyncio.run(analyze_existing_data())
    else:
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
        asyncio.run(start_scheduler())
